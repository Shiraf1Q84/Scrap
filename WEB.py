import os
import streamlit as st
import google.generativeai as genai
from PyPDF2 import PdfReader
import markdown
import re
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin, quote

# e-Gov æ³•ä»¤ API ã®è¨­å®š
API_VERSION = "1"
API_BASE_URL = f"https://elaws.e-gov.go.jp/api/{API_VERSION}"

# Streamlitãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Gemini PDFãƒ™ãƒ¼ã‚¹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ with Toggleable Search",
    page_icon="ğŸ“š",
    layout="wide",
    initial_sidebar_state="expanded",
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "documents" not in st.session_state:
    st.session_state.documents = []
if "checkbox_values" not in st.session_state:
    st.session_state.checkbox_values = {}
if "file_names" not in st.session_state:
    st.session_state.file_names = {}
if "next_file_id" not in st.session_state:
    st.session_state.next_file_id = 0
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–¢æ•°ã¯å¤‰æ›´ãªã—

def search_law_by_keyword_api(keyword):
    search_url = f"{API_BASE_URL}/lawdata;keyword={keyword}"
    try:
        response = requests.get(search_url)
        response.raise_for_status()
        data = response.json()
        if 'lawdata' in data and data['lawdata']:
            return data['lawdata']
        else:
            st.warning(f"ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ '{keyword}' ã«ä¸€è‡´ã™ã‚‹æ³•ä»¤ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return []
    except requests.RequestException as e:
        st.error(f"æ³•ä»¤ã®æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return []

def get_law_content_api(law_number):
    content_url = f"{API_BASE_URL}/articles;lawNum={law_number}"
    try:
        response = requests.get(content_url)
        response.raise_for_status()
        data = response.json()
        if 'articles' in data:
            return data['articles']
        else:
            st.warning(f"æ³•ä»¤ç•ªå· '{law_number}' ã®å†…å®¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return None
    except requests.RequestException as e:
        st.error(f"æ³•ä»¤å†…å®¹ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def search_law_by_keyword_web(keyword):
    base_url = "https://elaws.e-gov.go.jp"
    search_url = f"{base_url}/search/elawsSearch/elaws_search/lsg0100/?keyword={quote(keyword)}"
    try:
        response = requests.get(search_url)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        search_results = soup.find_all("div", class_="search-result-item")
        results = []
        for result in search_results:
            title_element = result.find("a", class_="result-title")
            if title_element:
                title = title_element.text.strip()
                url = urljoin(base_url, title_element['href'])
                results.append({'lawTitle': title, 'lawNum': url})
        return results
    except requests.RequestException as e:
        st.error(f"æ³•ä»¤ã®æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return []

def get_law_content_web(law_url):
    try:
        response = requests.get(law_url)
        response.raise_for_status()
        soup = BeautifulSoup(response.text, 'html.parser')
        law_content = soup.find("div", class_="law-content")
        if law_content:
            articles = law_content.find_all(["div", "p"], class_=re.compile("ArticleTitle|ArticleCaption|Paragraph"))
            return [{'articleTitle': article.get_text(strip=True)} for article in articles]
        else:
            st.warning("æ³•ä»¤ã®å†…å®¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return None
    except requests.RequestException as e:
        st.error(f"æ³•ä»¤å†…å®¹ã®å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return None

def extract_relevant_laws(query, model):
    prompt = f"""
    ä»¥ä¸‹ã®è³ªå•ã‹ã‚‰ã€é–¢é€£ã™ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹æ—¥æœ¬ã®æ³•ä»¤ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚
    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯3ã¤ã¾ã§æŠ½å‡ºã—ã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®ãƒªã‚¹ãƒˆã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
    é©åˆ‡ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯ã€ã€Œè©²å½“ãªã—ã€ã¨å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

    è³ªå•: {query}

    ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰:
    """
    
    response = model.generate_content(prompt)
    keywords = [kw.strip() for kw in response.text.split(',') if kw.strip() != 'è©²å½“ãªã—']
    return keywords

def law_specific_search(query, model, use_api):
    keywords = extract_relevant_laws(query, model)
    if not keywords:
        st.info("é–¢é€£ã™ã‚‹æ³•ä»¤ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        return []

    st.info(f"æŠ½å‡ºã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(keywords)}")
    
    search_results = []
    
    for keyword in keywords:
        if use_api:
            law_data = search_law_by_keyword_api(keyword)
            for law in law_data:
                law_number = law.get('lawNum')
                if law_number:
                    law_content = get_law_content_api(law_number)
                    if law_content:
                        search_results.append({
                            'title': law.get('lawTitle', 'ä¸æ˜ãªæ³•ä»¤'),
                            'number': law_number,
                            'content': law_content
                        })
        else:
            law_data = search_law_by_keyword_web(keyword)
            for law in law_data:
                law_url = law.get('lawNum')
                if law_url:
                    law_content = get_law_content_web(law_url)
                    if law_content:
                        search_results.append({
                            'title': law.get('lawTitle', 'ä¸æ˜ãªæ³•ä»¤'),
                            'number': law_url,
                            'content': law_content
                        })

    return search_results

def display_search_results(search_results, use_api):
    if search_results:
        st.subheader("é–¢é€£æ³•ä»¤æ¤œç´¢çµæœ")
        for result in search_results:
            with st.expander(f"{result['title']} ({'æ³•ä»¤ç•ªå·' if use_api else 'URL'}: {result['number']})"):
                for article in result['content']:
                    st.markdown(f"**{article.get('articleTitle', 'æ¡æ–‡')}**")
                    if use_api:
                        st.write(article.get('articleText', 'å†…å®¹ãªã—'))
    else:
        st.info("ã“ã®è³ªå•ã«é–¢é€£ã™ã‚‹æ³•ä»¤æ¤œç´¢çµæœã¯å¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")

def display_chat_interface(use_api):
    st.title("PDFãƒ™ãƒ¼ã‚¹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ with Toggleable Search (Gemini)")

    # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­å®š
    system_prompt = st.text_area(
        "ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        """
        ã‚ãªãŸã¯ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã«æä¾›ã•ã‚Œã¦ã„ã‚‹æ›¸é¡ã¨æœ€æ–°ã®æ³•ä»¤æ¤œç´¢çµæœã«åŸºã¥ã„ã¦æƒ…å ±ã‚’æä¾›ã™ã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚
        åˆ©ç”¨è€…ã®è³ªå•ã«ã€æ­£ç¢ºã‹ã¤ãªã‚‹ã¹ãè©³ç´°ã«ã€å‚è€ƒè³‡æ–™ã‚’å¼•ç”¨ã—ãªãŒã‚‰ç­”ãˆã¦ãã ã•ã„ã€‚
        æƒ…å ±ã¯800æ–‡å­—ä»¥ä¸Šã€4000æ–‡å­—ä»¥å†…ã«åã‚ã¦ãã ã•ã„ã€‚
        ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³å½¢å¼ã§è¦‹ã‚„ã™ãå‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        æƒ…å ±æºã‚’æ˜è¨˜ã—ã¦å›ç­”ã™ã‚‹ã‚ˆã†ã«åŠªã‚ã¦ãã ã•ã„ã€‚
        è¤‡æ•°ã®è§£é‡ˆãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œãã‚Œã‚’æç¤ºã—ã¦ãã ã•ã„ã€‚
        ä¸ãˆã‚‰ã‚ŒãŸæƒ…å ±ã ã‘ã§ã¯åˆ¤æ–­ã§ããªã„å ´åˆã«ã¯ã€åˆ¤æ–­ã§ããªã„æ—¨ã‚’ä¼ãˆã¦ãã ã•ã„ã€‚
        æ³•ä»¤ã®è§£é‡ˆãŒå¿…è¦ãªå ´åˆã¯ã€ãã®æ—¨ã‚’æ˜ç¢ºã«è¿°ã¹ã€å¯èƒ½ãªè§£é‡ˆã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚
        æ¤œç´¢çµæœãŒæä¾›ã•ã‚ŒãŸå ´åˆã€ãã‚Œã‚‰ã‚’å‚ç…§ã—ãªãŒã‚‰å›ç­”ã—ã¦ãã ã•ã„ã€‚
        """,
        height=300
    )

    # ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã¨æ¤œç´¢çµæœã‚’ä¸¦ã¹ã¦è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ã‚«ãƒ©ãƒ ã‚’ä½œæˆ
    chat_column, results_column = st.columns([2, 1])

    # ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®ã‚³ãƒ³ãƒ†ãƒŠ
    with chat_column:
        chat_container = st.container()

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ï¼ˆå¸¸ã«ç”»é¢ä¸‹éƒ¨ã«å›ºå®šï¼‰
        user_input = st.chat_input("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
        with chat_container:
            for message in st.session_state.chat_history:
                with st.chat_message(message["role"]):
                    st.markdown(message["content"])

    if user_input and api_key:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
        st.session_state.chat_history.append({"role": "user", "content": user_input})

        # Geminiãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
        model = genai.GenerativeModel(model_name)

        # ãƒã‚§ãƒƒã‚¯ã•ã‚Œã¦ã„ã‚‹ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ã¿ã‚’ä½¿ç”¨ã—ã¦ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
        context = ""
        for doc in st.session_state.documents:
            if st.session_state.checkbox_values.get(doc["id"], True):
                context += f"ãƒ•ã‚¡ã‚¤ãƒ«å: {st.session_state.file_names.get(doc['id'], 'Unknown File')}\n"
                context += f"å†…å®¹:\n{doc['content']}\n\n"

        # æ”¹å–„ã•ã‚ŒãŸæ³•ä»¤ç‰¹åŒ–æ¤œç´¢é–¢æ•°ã‚’ä½¿ç”¨
        search_results = law_specific_search(user_input, model, use_api)

        # æ¤œç´¢çµæœã‚’è¡¨ç¤º
        with results_column:
            display_search_results(search_results, use_api)

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä½œæˆ
        prompt = f"{system_prompt}\n\n"
        prompt += "å‚è€ƒæ–‡æ›¸:\n"
        prompt += f"{context}\n\n"
        prompt += f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {user_input}\n\n"
        prompt += "é–¢é€£æ³•ä»¤:\n"
        for result in search_results:
            prompt += f"æ³•ä»¤å: {result['title']} ({'æ³•ä»¤ç•ªå·' if use_api else 'URL'}: {result['number']})\n"
            for article in result['content'][:3]:  # æœ€åˆã®3ã¤ã®æ¡æ–‡ã®ã¿ã‚’å«ã‚ã‚‹
                prompt += f"æ¡æ–‡: {article.get('articleTitle', 'ä¸æ˜')}\n"
                if use_api:
                    prompt += f"å†…å®¹: {article.get('articleText', 'å†…å®¹ãªã—')[:200]}...\n\n"

        prompt += """
        ä¸Šè¨˜ã®æƒ…å ±ã‚’åŸºã«ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚é–¢é€£æ³•ä»¤ã‹ã‚‰ã®æƒ…å ±ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€å¿…ãšè©²å½“ã™ã‚‹æ³•ä»¤åã¨æ¡æ–‡ç•ªå·ã‚’æ˜è¨˜ã—ã¦ãã ã•ã„ã€‚
        æ³•ä»¤ã®è§£é‡ˆãŒå¿…è¦ãªå ´åˆã¯ã€ãã®æ—¨ã‚’æ˜ç¢ºã«è¿°ã¹ã€å¯èƒ½ãªè§£é‡ˆã‚’ç¤ºã—ã¦ãã ã•ã„ã€‚
        æƒ…å ±ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã¯ã€ã©ã®ã‚ˆã†ãªè¿½åŠ æƒ…å ±ãŒå¿…è¦ã‹ã‚’èª¬æ˜ã—ã¦ãã ã•ã„ã€‚
        """

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›ã®ãŸã‚ã®ç©ºã®ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã‚’ä½œæˆ
        with chat_column:
            with chat_container:
                with st.chat_message("assistant"):
                    response_placeholder = st.empty()

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ
        response = model.generate_content(prompt, stream=True)

        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡ºåŠ›
        full_response = ""
        for chunk in response:
            full_response += chunk.text
            response_placeholder.markdown(full_response + "â–Œ")

        # æœ€çµ‚çš„ãªå¿œç­”ã‚’è¡¨ç¤º
        response_placeholder.markdown(full_response)

        # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®å›ç­”ã‚’ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
        st.session_state.chat_history.append({"role": "assistant", "content": full_response})

    elif not api_key:
        st.warning("APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")

# UIéƒ¨åˆ†
left_column, right_column = st.columns([1, 3])

with left_column:
    # APIã‚­ãƒ¼å…¥åŠ›æ¬„
    st.title("Google API ã‚­ãƒ¼")
    api_key = st.text_input("APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", type="password")
    if st.button("APIã‚­ãƒ¼ã‚’è¨­å®š"):
        genai.configure(api_key=api_key)
        st.success("APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¾ã—ãŸ")

    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    model_name = st.selectbox("ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„:", ["gemini-1.5-pro", "gemini-pro"])

    # æ¤œç´¢æ–¹æ³•ã®ãƒˆã‚°ãƒ«
    use_api = st.toggle("e-Govæ³•ä»¤APIã‚’ä½¿ç”¨", value=True)

    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    uploaded_files = st.file_uploader(
        "PDFã¾ãŸã¯ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        accept_multiple_files=True,
        type=["pdf", "md"],
    )

    # ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†
    if uploaded_files:
        new_files = [file for file in uploaded_files if file.name not in st.session_state.file_names.values()]
        for uploaded_file in new_files:
            file_extension = os.path.splitext(uploaded_file.name)[1]
            if file_extension == ".pdf":
                text = extract_text_from_pdf(uploaded_file)
            elif file_extension == ".md":
                text = extract_text_from_markdown(uploaded_file)
            else:
                st.warning(f"æœªå¯¾å¿œã®ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã§ã™: {uploaded_file.name}")
                continue

            file_id = str(st.session_state.next_file_id)
            st.session_state.next_file_id += 1
            st.session_state.documents.append({"id": file_id, "content": text})
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ä¿å­˜/æ›´æ–°
            st.session_state.file_names[file_id] = uploaded_file.name
            
# ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®åˆæœŸçŠ¶æ…‹ã‚’è¨­å®š
            st.session_state.checkbox_values[file_id] = True

        if new_files:
            st.success(f"{len(new_files)}å€‹ã®æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¾ã—ãŸã€‚")

    # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã®è¡¨ç¤º
    st.subheader("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«")
    for doc in st.session_state.documents:
        file_id = doc["id"]
        file_name = st.session_state.file_names.get(file_id, "Unknown File")
        checked = st.checkbox(
            file_name,
            value=st.session_state.checkbox_values.get(file_id, True),
            key=f"checkbox_{file_id}"
        )
        # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®çŠ¶æ…‹ã‚’æ›´æ–°
        st.session_state.checkbox_values[file_id] = checked

with right_column:
    display_chat_interface(use_api)
    
# ãƒ¡ã‚¤ãƒ³é–¢æ•°ã®å‘¼ã³å‡ºã—
if __name__ == "__main__":
    st.sidebar.title("è¨­å®š")
    st.sidebar.info("å·¦å´ã®ãƒ‘ãƒãƒ«ã§è¨­å®šã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")